<!DOCTYPE html>
<html lang='en' ><meta charset="utf-8">
<meta name="viewport" content="width=device-width">


<title>Analyzing Gdev | Better Tomorrow with Computer Science</title>
<link rel="stylesheet" href="/css/eureka.min.css">
<script defer src="/js/eureka.min.js"></script>

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&family=Noto+Serif+SC:wght@400;600;700&display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/styles/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.8.6/css/academicons.min.css"
   crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/highlight.min.js"
   crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js"
   integrity="sha256-uNYoXefWRqv&#43;PsIF/OflNmwtKM4lStn9yrz2gVl6ymo="  crossorigin></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
   integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3&#43;Aro6EYUG4&#43;cU&#43;KJWu/X"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" 
  integrity="sha384-g7c&#43;Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI&#43;sEnkvrMWph2EDg4"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
   integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC&#43;Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>
<link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158110335-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'UA-158110335-1');
</script>


<link rel="icon" type="image/png" sizes="32x32" href="/umich_hu6c99b92144fcbc4e30752e6c6d9a0d50_18545_32x32_fill_box_center_3.png">
<link rel="apple-touch-icon" sizes="180x180" href="/umich_hu6c99b92144fcbc4e30752e6c6d9a0d50_18545_180x180_fill_box_center_3.png">

<meta name="description"
  content="Gdev Gdev is an open-source CUDA software, containing device drivers, CUDA runtimes, CUDA/PTX compilers, and so on.">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Posts",
      "item":"/posts/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"Analyzing Gdev",
      "item":"/2017-04-27/analyzing-gdev/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/2017-04-27/analyzing-gdev/"
    },
    "headline": "Analyzing Gdev | Better Tomorrow with Computer Science","datePublished": "2017-04-27T22:35:30+09:00",
    "dateModified": "2017-04-27T22:35:30+09:00",
    "wordCount":  2697 ,
    "publisher": {
        "@type": "Person",
        "name": "Insu Jang",
        "logo": {
            "@type": "ImageObject",
            "url": "/umich.png"
        }
        },
    "description": "Gdev Gdev is an open-source CUDA software, containing device drivers, CUDA runtimes, CUDA\/PTX compilers, and so on."
}
</script><meta property="og:title" content="Analyzing Gdev | Better Tomorrow with Computer Science" />
<meta property="og:type" content="article" />


<meta property="og:image" content="/umich.png">


<meta property="og:url" content="/2017-04-27/analyzing-gdev/" />




<meta property="og:description" content="Gdev Gdev is an open-source CUDA software, containing device drivers, CUDA runtimes, CUDA/PTX compilers, and so on." />




<meta property="og:locale" content="en" />




<meta property="og:site_name" content="Better Tomorrow with Computer Science" />






<meta property="article:published_time" content="2017-04-27T22:35:30&#43;09:00" />


<meta property="article:modified_time" content="2017-04-27T22:35:30&#43;09:00" />



<meta property="article:section" content="posts" />


<meta property="article:tag" content="cuda" />

<meta property="article:tag" content="research" />





<meta property="og:see_also" content="/2017-04-27/gpu-architecture-overview/" />

<meta property="og:see_also" content="/2017-04-03/pci-express-i/o-system/" />

<meta property="og:see_also" content="/2017-04-27/introduction-to-vfio/" />

<meta property="og:see_also" content="/2017-04-21/hooking-an-sgx-encls-leaf-function-call-from-kvm/" />

<meta property="og:see_also" content="/2017-04-05/intel-sgx-instructions-in-enclave-initialization/" />

<meta property="og:see_also" content="/2017-04-03/intel-sgx-protection-mechanism/" />



<body class="flex flex-col min-h-screen">
  <header class="fixed flex items-center w-full min-h-16 pl-scrollbar z-50 bg-secondary-bg shadow-sm">
    <div class="w-full max-w-screen-xl mx-auto"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if ((storageColorScheme == 'Auto' && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap p-4">
    <a href="/" class="mr-6 text-primary-text font-bold">Better Tomorrow with Computer Science</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/#about"
                class="block mt-4 md:inline-block md:mt-0  hover:text-eureka mr-4">About</a>
            <a href="/posts/"
                class="block mt-4 md:inline-block md:mt-0  hover:text-eureka mr-4">Posts</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-sun"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka">Light</span>
                    <span class="px-4 py-1 hover:text-eureka">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka">Auto</span>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == 'Auto') {
        element.firstElementChild.classList.remove('fa-sun')
        element.firstElementChild.setAttribute("data-icon", 'adjust')
        element.firstElementChild.classList.add('fa-adjust')
        document.addEventListener('DOMContentLoaded', () => {
            switchMode('Auto')
        })
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-sun')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }
    
    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
    });
</script></div>
  </header>
  <main class="flex-grow pt-16">
      <div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto">


<div class="lg:pt-12"></div>
<div
    class="col-span-2 lg:col-start-2 lg:col-span-6 bg-secondary-bg rounded px-6 py-8">
    <h1 class="font-bold text-3xl text-primary-text">Analyzing Gdev</h1>
    <div class="mr-6 my-2">
    <span>Apr 27, 2017</span>
</div>




    
    
    

    <div class="content">
        <h2 id="gdev">Gdev</h2>
<p>Gdev is an open-source CUDA software, containing device drivers, CUDA runtimes, CUDA/PTX compilers, and so on.</p>
<p>You can download it from <a href="https://github.com/shinpei0208/gdev">[here]</a>.</p>
<p>Detail implementations are described in the other paper that the author wrote, <em>Implementing Open-Source CUDA Runtime</em>. (<a href="http://www.ertl.jp/~shinpei/papers/pro13.pdf">link</a>)</p>
<h3 id="internal-implementation">Internal Implementation</h3>
<p><img src="/assets/images/170427/gdev_internal.png" alt="gdev_internal">{: .center-image}</p>
<ul>
<li>Implementation of Gdev</li>
</ul>
<p>Gdev uses the existing open-source NVIDIA device driver, Nouveau. It also supports NVIDIA proprietary drivers and pscnv as well, pscnv is not maintained and NVIDIA driver is not an open-source. Gdev mainly works well with Nouveau.</p>
<p>It supports user-space runtime, so it can perform a GPGPU application with only Nouveau device driver. However, it requires root permission to be executed, I uses additional device driver called gdev. To use it, compile Gdev with the following commands.</p>
<pre><code>$ cmake -H. -Brelease -Ddriver=nouveau -Duser=OFF -Druntime=ON
$ make -C release -j 8
$ sudo make -C release install
</code></pre>
<p>Different from the instruction in the author&rsquo;s Github, I set user parameter OFF to make driver backend reside in kernel space, so running CUDA application do not require root permission.</p>
<h3 id="code-review">Code Review</h3>
<p>Gdev follows GPU&rsquo;s resource management model, which is illustrated in <a href="/2017-04-27/gpu-architecture-overview/">[here]</a>. So it allocates memory regions in MMIO, writes commands into that MMIO region, and so on. This section will analyze function calls from a basic example CUDA application.</p>
<p>The sample application calls CUDA device API functions as follows.</p>
<pre><code>cuInit()
cuDeviceGet()
cuCtxCreate()
cuModuleLoad()
cuModuleGetFunction()
cuFuncSetBlockShape()

cuMemAlloc(a[])
cuMemAlloc(b[])
cuMemAlloc(c[])
cuMemcpyHtoD(a[])
cuMemcpyHtoD(b[])

cuParamSeti() ...
cuParamSetSize()
cuLaunchGrid()
cuCtxSynchronize()
cuMemcpyDtoH(c[])

cuMemFree(a[])
cuMemFree(b[])
cuMemFree(c[])

cuModuleUnload()
cuCtxDestroy()
</code></pre>
<h4 id="0-additional-functions-in-nouveau">0. Additional Functions in Nouveau</h4>
<p>All gdev functions call functions additionally implemented in Nouveau (<code>/linux/drivers/gpu/drm/nouveau/gdev_interface.c</code>). This file does not exist by default and Linux kernel should be patched by a patcher that the author provided.</p>
<pre><code class="language-c">int gdev_drv_vspace_alloc(struct drm_device *drm, uint64_t size, struct gdev_drv_vspace *drv_vspace) {
    u32 arg0 = 0xbeef0201;
    u32 arg1 = 0xbeef0202;

    printk(&quot;%s: creating a new vspace. size: 0x%lx\n&quot;,
            __func__, size);
    nouveau_channel_new(nvdrm, &amp;nvdrm-&gt;client, NVDRM_DEVICE, NVDRM_CHAN + 2, arg0, arg1, &amp;chan);
    ...
}

int gdev_drv_chan_alloc(struct drm_device *drm, struct gdev_drv_vspace *drv_vspace, struct gdev_drv_chan *drv_chan) {
    // It initializes FIFO push buffer(`drv_chan-&gt;pb_xx`) and FIFO indirect buffer(`drv_chan-&gt;ib_xx`).
    pb_order = 16; // it's hardcoded.
    pb_bo = chan-&gt;push.buffer;
    pb_base = chan-&gt;push.vma.offset;
    ...
    pb_size = (1 &lt;&lt; pb_order);
    ...
    printk(&quot;%s: allocating a channel. &quot;
           &quot;push buffer addr: 0x%lx, size: 0x%lx. &quot;
           &quot;indirect buffer addr: 0x%lx\n&quot;,
           __func__, pb_base, pb_size, ib_base);

    // FIFO init: it has already been done in gdev_vas_new().
}

int gdev_drv_bo_alloc(struct drm_device *drm, uint64_t size, uint32_t drv_flags, struct gdev_drv_vspace *drv_vspace, struct gdev_drv_bo *drv_bo) {
    printk(&quot;%s: allocating a new buffer object. size: 0x%lx\n&quot;,
           __func__, size);

    nouveau_bo_new(drm, size, 0, flags, 0, 0, NULL, &amp;bo);

    if (drv_flags &amp; GDEV_DRV_BO_MAPPABLE) nouveau_bo_map(bo);

    // allocate virtual address space, if requested.
    if (drv_flags &amp; GDEV_DRV_BO_VSPACE){
        vma = kzalloc(sizeof(*vma), GFP_KERNEL);
        nouveau_bo_vma_add(bo, client-&gt;vm, vma);
        drv_bo-&gt;addr = vma-&gt;offset;
    }

    // address, size, and map.
    drv_bo-&gt;map = bo-&gt;kmap.virtual;
    drv_bo-&gt;size = bo-&gt;bo.mem.size;
    driv_bo-&gt;priv = bo;
}
</code></pre>
<h4 id="1-cuctxcreate">1. <code>cuCtxCreate()</code></h4>
<p>Defined in <code>/gdev/cuda/driver/context.c</code>.</p>
<pre><code class="language-c">CUresult cuCtxCreate_v2(CUcontext *pctx, unsigned int flags, CUdevice dev) {
    handle = gopen(minor);

    // set to the current context.
    cuCtxPushCurrent(ctx);

    // get the CUDA-specific device information.
    gquery(handle, GDEV_QUERY_CHIPSET, &amp;cuda_info-&gt;chipset);

    cuDeviceGetAttribute(&amp;mp_count, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUND, dev);

    return CUDA_SUCCESS;
}
</code></pre>
<p>As <code>cuCtxPushCurrent()</code> and <code>gquery()</code> does not use any Nouveau driver function, they will be passed.</p>
<h5 id="1-1-gopen">1-1. <code>gopen()</code></h5>
<p>When <code>cuCtxCreate()</code> is called, the selected gdev device is opened. The function for this purpose is <code>gopen()</code>. It is implemented in <code>/gdev/common/gdev_api.c</code> and will be copied into <code>/gdev/release/mod/gdev/gdev_api.c</code> after performing <code>cmake</code>.</p>
<p>It opens the device as well as allocates some memory regions for this context.</p>
<pre><code class="language-c">struct gdev_handle *gopen (int minor) {
    // open the specified device.
    printk(&quot;%s: opening minor device number %d\n&quot;, __func__, minor);
    struct gdev_device* gdev = gdev_dev_open(minor);

    // create a new virtual address space (VAS) object.
    printk(&quot;%s: creating a new virtual address space object. size: 0x%lx\n&quot;,
            __func__, GDEV_VAS_SIZE);
    gdev_vas_t* vas = gdev_vas_new(gdev, GDEV_VAS_SIZE, h);

    // create a new GPU context object.
    printk(&quot;%s: creating a new GPU context.\n&quot;, __func__);
    gdev_ctx_t* ctx = gdev_ctx_new(gdev, vas);

    // allocate static bounce bound buffer objects.
    printk(&quot;%s: allocating static bounce bound buffer. size: 0x%lx\n&quot;,
            __func__, GDEV_CHUNK_DEFAULT_SIZE);
    gdev_mem_t* dma_mem = __malloc_dma(vas, GDEV_GDEV_CHUNK_DEFAULT_SIZE, h-&gt;pipeline_count);

    GDEV_PRINT(&quot;Opened gdev%d\n&quot;, minor);
}
</code></pre>
<p>Note that <code>gdev_drv_chan_alloc()</code> says FIFO buffers are initiated by <code>gopen()</code>, not by itself. To check this, I also added a printk call in <code>nouveau_fifo_channel_create_()</code> function in <code>linux/drivers/gpu/drm/nouveau/core/engine/fifo/base.c</code>.</p>
<h5 id="result">Result</h5>
<pre><code>gopen: opening minor device 0
gopen: creating a new virtual address space object. size: 0x10000000000
gdev_drv_vspace_alloc: creating a new vspace. size: 0x10000000000
nouveau_fifo_channel_create_: channel addr: 0xe8002000, len: 0x1000.

gopen: creating a new GPU context. [1]
gdev_drv_chan_alloc: allocating a channel. push buffer addr: 0x103f5000, size: 0x10000. indirect buffer addr: 0x10405000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x10000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x8

gopen: allocating static bounce bound buffer. size: 0x40000 [2]
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x40000 (memory allocated at host for DMA)
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x40000 (memory allocated at host for DMA)
[gdev] Opened gdev0
</code></pre>
<p>Note that FIFO buffer is created by <code>gopen()</code>.</p>
<h5 id="1-gdev_ctx_new">[1] gdev_ctx_new()</h5>
<p><code>gdev_ctx_new()</code> is defined in <code>/gdev/common/gdev_nvidia.c</code>, and calls <code>gdev_raw_ctx_new()</code> defined in <code>/gdev/mod/gdev/gdev_drv_nvidia.c</code>, which allocates three buffers: command FIFO, fence buffer, and notify buffer.</p>
<p>Actually, it creates one more buffer (desc buffer), however, it is allocated for Kepler GPU architecture, which will not be used by me.</p>
<pre><code class="language-c">struct gdev_ctx *gdev_raw_ctx_new(struct gdev_device *gdev, struct gdev_vas *vas) {
    struct gdev_ctx* ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
    gdev_drv_chan_alloc(drm, &amp;vspace, &amp;chan);
    ...
    // fence buffer.
    flags = GDEV_DRV_BO_SYSRAM | GDEV_DRV_BO_VSPACE | GDEV_DRV_BO_MAPPABLE;
    gdev_drv_bo_alloc(drm, GDEV_FENCE_BUF_SIZE, flags, &amp;vspace, $fbo);

    // notify buffer.
    flags = GDEV_DRV_BO_VRAM | GDEV_DRV_BO_VSPACE;
    gdev_drv_bo_alloc(drm, 8 /* 64 bits */, flags, &amp;vspace, &amp;nbo);

    // compute desc buffer.
    flags = GDEV_DRV_BO_SYSRAM | GDEV_DRV_BO_VSPACE | GDEV_DRV_BO_MAPPABLE;
    gdev_drv_bo_alloc(drm, sizeof(struct gdev_nve4_compute_desc), flags, &amp;vpsace, &amp;dbo);

    ...
    // allocating PGRAPH context for M2MF
    gdev_drv_subch_alloc(drm, ctx-&gt;pctx, 0xbeef323f, m2mf_class, &amp;m2mf);

    return ctx;
}
</code></pre>
<p>After adding <code>printk()</code>s in <code>gdev_raw_ctx_new()</code>, the result is as follows.</p>
<pre><code>gdev_drv_chan_alloc: allocating a channel. push buffer addr: 0x103f5000, size: 0x10000. indirect buffer addr: 0x10405000
gdev_raw_ctx_new: fence buffer allocation with size: 0x10000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x10000
gdev_raw_ctx_new: notify buffer allocation with size: 0x8
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x8
...
</code></pre>
<h5 id="2-__malloc_dma">[2] <code>__malloc_dma()</code></h5>
<p>The result says that <code>__malloc_dma()</code> allocates two buffer objects and memory regions each size of which is 0x40000.</p>
<p>Here is a detailed implementation of <code>__malloc_dma()</code>. It is located in <code>/gdev/common/gdev_api.c</code>.</p>
<pre><code class="language-c">static gdev_mem_t** __malloc_dma(gdev_vas_t *vas, uint64_t size, int p_count) {
    gdev_mem_t** dma_mem;
    int i;

    for (i=0; i&lt;p_count; i++) dma_mem[i] = gdev_mem_alloc(vas, size, GDEV_MEM_DMA);
    ...
}
</code></pre>
<p><code>gdev_mem_alloc()</code> calls <code>gdev_raw_mem_alloc()</code>, which calls <code>gdev_drv_bo_alloc()</code>. After printing <code>p_count</code>, I found that <code>p_count</code> is 2. Hence two memory and buffer objects are allocated.</p>
<h4 id="2-cumoduleload">2. <code>cuModuleLoad()</code></h4>
<p>Defined in <code>/gdev/cuda/driver/module.c</code>.</p>
<pre><code class="language-c">CUresult cuModuleLoad(CUmodule *module, const char *fname) {
    ...
    // load the cubin image from the given object file.
    gdev_cuda_load_cubin_file(mod, fname);

    // construct the kernels based on the cubin data.
    gdev_cuda_construct_kernels(mod, &amp;ctx-&gt;cuda_info);

    // allocate (local) static data memory.
    printf(&quot;%s: allocating local static data memory. size: 0x%lx\n&quot;,
          __func__, mod-&gt;sdata_size);
    gmalloc(handle, mod-&gt;sdata_size);

    // allocate the static data information for each kernel.
    gdev_cuda_locate_sdata(mod);

    // allocate code and constant memory.
    printf(&quot;%s: allocating code and constant memory size. size: 0x%lx\n&quot;,
           __func__, mode-&gt;code_size);
    gmalloc(handle, mod-&gt;code_size);

    // locate the code information for each kernel.
    gdev_cuda_locate_code(mod);

    // transfer the code and constant memory onto the device.
    bnf_buf = malloc(mod-&gt;cuda_size);
    gdev_cuda_memcpy_code(mod, bnc_buf);
    gmemcpy_to_device(handle, mod-&gt;code_addr, bnc_buf, mod-&gt;code_size);
    ...
}
</code></pre>
<p>Note that this is a runtime library, not a part of gdev device driver, so <code>printf()</code> should be used instead of using <code>printk()</code>. Hence results are divided into userspace part, and kernel dmesg part. Note that I also added more <code>printk()</code> function calls in <code>gdev_raw_mem_alloc_dma()</code> and <code>gdev_raw_mem_alloc()</code>, which are implemented in <code>/gdev/common/gdev_nvidia_mem.c</code>. These functions are called by <code>gmalloc()</code>, as follows.</p>
<pre><code class="language-c">uint64_t gmalloc(struct gdev_handle *h, uint64_t size) {
    ...
    printk(&quot;%s: allocating device memory by calling gdev_mem_alloc. size: 0x%lx\n&quot;,
           __func__, size);
    mem = gdev_mem_alloc(vas, size, GDEV_MEM_DEVICE);
    ...
}
</code></pre>
<pre><code class="language-c">struct gdev_mem *gdev_mem_alloc(struct gdev_vas *vas, uint64_t size, int type) {
    switch (type) {
    case GDEV_MEM_DEVICE:
        mem = gdev_raw_mem_alloc(vas, size);
        break;
    case GDEV_MEM_DMA:
        mem = gdev_raw_mem_alloc_dma(vas, size);
        break;
    default:
        goto fail;
    }
}
</code></pre>
<h5 id="result-1">Result</h5>
<pre><code>stdout
cuModuleLoad: allocating local static data memory. size: 0xc00000
cuModuleLoad: code and constant memory size: 0x20300
</code></pre>
<pre><code>dmesg
__malloc_dma: allocating 2 memory regions with size 0x40000
gdev_raw_mem_alloc_dma: allocating memory at host for DMA. size: 0x40000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x40000
gdev_raw_mem_alloc_dma: allocating memory at host for DMA. size: 0x40000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x40000

gmalloc: allocating device memory by calling gdev_mem_alloc. size: 0xc00000
gdev_raw_mem_alloc: allocing memory at device. size: 0xc00000
gdev_drv_bo_alloc: allocating a new buffer object. size: 0xc00000

gmalloc: allocating device memory by calling gdev_mem_alloc. size: 0x20300
gdev_raw_mem_alloc: allocating memory at device. size: 0x20300
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x20300
</code></pre>
<p>I understand two <code>gmalloc()</code>s are called for static data and code/constant memory, but where does two buffer object allocation come from?</p>
<p>This <code>__malloc_dma()</code> call comes from <code>gtune()</code>, defined in <code>/gdev/common/gdev_api.c</code>, which is called by <code>gopen()</code> in CUDA runtime library (defined in <code>/gdev/lib/kernel/gdev_lib.c</code>).</p>
<pre><code>struct gdev_handle *gopen(int minor) {
    ...
    sprintf(devname, &quot;/dev/gdev%d&quot;, minor);
    fd = open(devname, O_RDWR);
    ...
    // chunk size of 0x40000 seems best when using OS runtime.
    gtune(h, GDEV_TUNE_MEMCPY_CHUNK_SIZE, 0x40000);
}
</code></pre>
<p><code>/gdev/common/gdev_api.c</code></p>
<pre><code>int gtune (struct gdev_handle *h, uint32_t type, uint32_t value) {
    switch(type){
    case GDEV_TUNE_MEMCPY_PIPELINE_COUNT:
        ...
    case GDEV_TUNE_MEMCPY_CHUNK_SIZE:
        h-&gt;dma_mem = __malloc_dma(h-&gt;vas, h-&gt;chunk_size, h-&gt;pipeline_count);
    }
}
</code></pre>
<p>When <code>fd = open(devname, O_RDWR)</code> is called, the control is transferred to gdev device driver, and calls <code>gdev_open()</code>, defined in <code>/gdev/mod/gdev/gdev_fops.c</code>, which calls <code>gopen()</code> function, defined in the gdev device driver, not runtime library.</p>
<p>Hence, actually, this allocations are parts of <code>cuCtxCreate()</code>.<br>
The call flow is as follows. <code>cuCtxCreate()</code> -&gt; <code>gopen()</code> (in CUDA runtime) -&gt; <code>gdev_open()</code> (in gdev device driver) -&gt; <code>gopen()</code> (in gdev device drvier).</p>
<h4 id="3-cumemalloc">3. <code>cuMemAlloc()</code></h4>
<pre><code>// a[]
gmalloc: allocating device memory by calling gdev_mem_alloc. size: 0x24
gdev_raw_mem_alloc: allocating memory at device. size: 0x24
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x24

// b[]
gmalloc: allocating device memory by calling gdev_mem_alloc. size: 0x24
gdev_raw_mem_alloc: allocating memory at device. size: 0x24
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x24

// c[]
gmalloc: allocating device memory by calling gdev_mem_alloc. size: 0x24
gdev_raw_mem_alloc: allocating memory at device. size: 0x24
gdev_drv_bo_alloc: allocating a new buffer object. size: 0x24
</code></pre>
<h4 id="4-cumemcpyhtod">4. <code>cuMemcpyHtoD()</code></h4>
<h5 id="4-1-how-gdev-transfer-the-data-into-device">4-1. How gdev transfer the data into device?</h5>
<p>Defined in <code>/gdev/cuda/driver/memory.c</code>.</p>
<pre><code class="language-c">CUresult cuMemcpyHtoD_v2 (CUdeviceptr dstDevice, const void *srcHost, unsigned int ByteCount) {
    ...
    gmemcpy_to_device(handle, dst_addr, src_buf, size);
    return CUDA_SUCCESS;
}
</code></pre>
<p><code>/gdev/common/gdev_api.c</code></p>
<pre><code class="language-c">int gmemcpy_to_device(struct gdev_handle *h, uint64_t dst_addr, const void *src_buf, uint64_t size) {
    return __gmemcpy_to_device(h, dst_addr, src_buf, size, NULL, __ f_memcpy);
}

// a wrapper function of gmemcpy_to_device().
static int __gmemcpy_to_device (struct gdev_handle *h, uint64_t dst_addr, const void *src_buf, uint64_t size, uint32_t *id, int (*host_copy)(void*, const void*, uint32_t)) {
    mem = gdev_mem_lookup_by_addr(vas, dst_addr, GDEV_MEM_DEVICE);
    gdev_mem_lock(mem);
    __gmemcpy_to_device_locked(ctx, dst_addr, src_buf, size, id, ch_size, p_count, vas, mem, dma_mem, host_copy);
    gdev_mem_unlock(mem);
    ...
}

static int __gmemcpy_to_device_locked(gdev_ctx *ctx, uint64_t dst_addr, const void *src_buf, uint64_t size, uint32_t *id, uint32_t ch_size, int p_count, gdev_vas_t *vas, gdev_mem_t *mem, gdev_mem_t **dma_mem, int (*host_copy)(void*, const void*, uint32_t)) {
    if (size &lt;= 4 &amp;&amp; mem-&gt;map)
        gdev_write32(mem, dst_addr, ((uint32_t*)src_buf)[0]);

    // GDEV_MEMCPY_IOWRITE_LIMIT = 0x400000 (4MB) defined in mod/gdev/gdev_conf.h
    else if (size &lt;= GDEV_MEMCPY_IOWRITE_LIMIT &amp;&amp; mem-&gt;map)
        gdev_write(mem, dst_addr, src_buf, size);

    else if ((hmem = gdev_mem_lookup_by_buf(vas, src_buf, GDEV_MEM_DMA))) {
        __gmemcpy_dma_to_device(ctx, dst_addr, hmem-&gt;addr, size, id);
    }

    else {
        // prepare bounce buffer memory.
        // In a test configuration, it is not called.
        if(!dma_mem) bmem = __malloc_dma(vas, __min(size, ch_size), p_count);

        if (p_count &gt; 1 &amp;&amp; size &gt; ch_size) __gmemcpy_to_device_p(ctx, dst_addr, src_buf, size, ch_size, p_count, bmem, host_copy);
        else __gmemcpy_to_device_np(dst_addr, src_buf, size, ch_size, bmem, host_copy);

        if(!dma_mem) __free_dma(bmem, p_count);
    }
}
</code></pre>
<p>The last function calls <code>gdev_write32()</code> or <code>gdev_write()</code>, both are defined in <code>/mod/gdev/gdev_nvidia_compute.c</code>. Also you can see that gdev transfers data in different ways in terms of its size.</p>
<ul>
<li>If size is less than 4 bytes, it just write 4 bytes (32 bits) via MMIO.</li>
<li>If size is less than 4MB, it uses MMIO (maybe).</li>
<li>Else, it transfers via DMA.</li>
</ul>
<p>This strategy is well explained in the paper <em>Data Transfer Matters for GPU Computing</em> [[link](http://www.ertl.jp/~shinpei/papers/icpads13.pdf)]. The author of Gdev is a coworker of this paper.</p>
<p><code>gdev_write32()</code> and <code>gdev_write()</code> call <code>gdev_raw_write32()</code> and <code>gdev_raw_write()</code> respectively, defined in <code>/mod/gdev/gdev_drv_nvidia.c</code>.</p>
<pre><code class="language-c">void gdev_raw_write32 (struct gdev_mem *mem, uint64_t addr, uint32_t val) {
    bo.addr = mem-&gt;addr;
    bo.size = mem-&gt;size;
    bo.map = mem-&gt;map;
    gdev_drv_write32(drm, &amp;vspace, &amp;bo, offset, val);
}

void gdev_raw_write (struct gdev_mem *mem, uint64_t addr, const void *buf, uint32_t size) {
    bo.addr = mem-&gt;addr;
    bo.size = mem-&gt;size;
    bo.map = mem-&gt;map;
    gdev_drv_write(drm, &amp;vspace, &amp;bo, offset, size, buf);
}
</code></pre>
<p><code>/linux/drivers/gpu/drm/nouveau/gdev_interface.c</code></p>
<pre><code class="language-c">int gdev_drv_write32 (struct drm_device *drm, struct gdev_drv_vspace *drv_vspace, struct gdev_drv_bo *drv_bo, uint64_t offset, uint32_t val) {
    if(drv_bo-&gt;map) iowrite32_native(val, drv_bo-&gt;map + offset);
    return 0;
}

int gdev_drv_write (struct drm_device *drm, struct gdev_drv_vspace *drv_vspace, struct gdev_drv_bo *drv_bo, uint64_t offset, uint64_t size, const void *buf) {
    if(drv_bo-&gt;map) memcpy_toio(drv_bo-&gt;map + offset, buf, size);
}
</code></pre>
<p><code>/linux/include/asm-generic/io.h</code></p>
<pre><code class="language-c">static inline void memcpy_toio(volatile void __ iomem *addr, const void*buffer, size_t size) {
    memcpy(__ io_virt(addr), buffer, size);
}

static inline void iowrite32 (u32 value, volatile void __ iomem *addr) {
    writel(value, addr);
}
</code></pre>
<p>These functions are for MMIO defined in Linux kernel. For more information, visit [[here](http://www.makelinux.net/ldd3/chp-9-sect-4)].</p>
<h5 id="4-2-how-gdev-get-the-mmio-address-for-the-variable">4-2. How gdev get the MMIO address for the variable?</h5>
<p>Now, we understand that the target address is <code>drv_bo-&gt;map + offset (gdev_drv_write())</code>, the first one of which comes from <code>mem-&gt;map(gdev_raw_write())</code>, which returns from <code>gdev_mem_lookup_by_addr()</code> in <code>__gmemcpy_to_device()</code>.</p>
<p>Seeing <code>__gmemcpy_to_device()</code> again, the function works as follows.</p>
<pre><code class="language-c">static int __gmemcpy_to_device (struct gdev_handle *h, uint64_t dst_addr, const void *src_buf, uint64_t size, uint32_t *id, int (*host_copy)(void*, const void*, uint32_t)) {
    mem = gdev_mem_lookup_by_addr(vas, dst_addr, GDEV_MEM_DEVICE);
    __gmemcpy_to_device_locked(ctx, dst_addr, src_buf, size, id, ch_size, p_count, vas, mem, dma_mem, host_copy);
    ...
}
</code></pre>
<p>Keep in mind that, all software <mark>must</mark> access to memory including MMIO via virtual address, not physical address. hence, what <code>gdev_mem_lookup_by_addr</code> returns is a virtual address mapped to <code>dst_addr</code>. For <code>a[]</code>, printing the information is as follows.</p>
<pre><code class="language-c">gdev_mem *mem = gdev_mem_lookup_by_addr(vas, dst_addr, GDEV_MEM_DEVICE);
printk(&quot;%s: gdev_mem_lookup_by_addr returns mem-&gt;map: 0x%lx, dst_addr: 0x%lx\n&quot;,
        __func__, mem-&gt;map, dst_addr);
</code></pre>
<pre><code>dmesg

// cuMemAlloc for a[]
gmalloc: calling gdev_mem_alloc, size: 0x24.
gdev_raw_mem_alloc: allocating memory at device. size: 0x24
__gdev_raw_mem_alloc: allocating memory of 0x24 bytes at addr 0x10554000

...

// cuMemcpyHtoD for a[]
__gmemcpy_to_device: gdev_mem_lookup_by_addr returns mem-&gt;map: 0xffffc90010e9c000, dst_addr: 0x10554000
</code></pre>
<p>As the name of the function is <code>lookup_by_addr</code>, and <code>dst_addr</code> is given as a parameter, <code>gdev_mem</code> structure would store both physical address and virtual address mapped to it.</p>
<p>For more detail, let&rsquo;s see implementation of the function to see how it get objects with <code>dst_addr</code>. It is implemented in <code>/gdev/common/gdev_nvidia_mem.c</code>.</p>
<pre><code class="language-c">struct gdev_mem *gdev_mem_lookup_by_addr(struct gdev_vas *vas, uint64_t addr, int type) {
    switch (type){
    case GDEV_MEM_DEVICE:
        gdev_list_for_each (mem, &amp;vas-&gt;mem_list, list_entry_heap) {
            if (addr &gt;= mem-&gt;addr) &amp;&amp; (addr &lt; mem-&gt;addr + mem-&gt;size)) break;
        }
        ...
    }
    return mem;
}
</code></pre>
<p>It compares <code>dst_addr</code> with <code>mem-&gt;addr</code> for all <code>gdev_mem</code> objects.</p>
<p>Then let&rsquo;s figure out when <code>gdev_mem</code> object is created for each data. One good starting point would be <code>__gdev_raw_mem_alloc()</code>, defined in <code>/gdev/mod/gdev/gdev_drv_nvidia.c</code>.</p>
<pre><code class="language-c">static intline struct gdev_mem *__gdev_raw_mem_alloc(struct gdev_vas *vas, uint64_t size, uint32_t flags) {
    struct gdev_mem* mem;
    mem = kzalloc(sizeof(*mem), GFP_KERNEL);
    gdev_drv_bo_alloc(drm, size, flags, &amp;vpsace, &amp;bo);
    printk(&quot;%s: allocating memory of 0x%lx bytes at addr 0x%lx\n&quot;,
           __func__, size, bo.addr);
    mem-&gt;addr = bo.addr;
    mem-&gt;size = bo.size;
    mem-&gt;map = bo.map;
    mem-&gt;bo = bo.priv;
    mem-&gt;padata = (void*)drm;

    return mem;
}

__gdev_raw_mem_alloc: allocating memory of 0x24 bytes at addr 0x10554000
</code></pre>
<p>Hence <code>mem-&gt;addr = bo.addr</code>. Then how <code>bo.addr</code> is set? It is set in <code>gdev_drv_bo_alloc()</code> defined in <code>/linux/drivers/gpu/drm/nouveau/gdev_interface.c</code>.</p>
<pre><code class="language-c">int gdev_drv_bo_alloc (struct drm_device *drm, uint64_t size, uint32_t drv_flags, struct gdev_drv_vspace *drv_vspace, struct gdev_drv_bo *drv_bo) {
    struct nouveau_bo* bo;
    nouveau_bo_new(drm, size, 0, flags, 0, 0, NULL, &amp;bo);
    ...
    nouveau_vma* vma - kzalloc(sizeof(*vma), GFP_KERNEL);
    nouveau_bo_vma_add(bo, client-&gt;vm, vma);
    drv_bo-&gt;addr = vma-&gt;offset;
    // otherwise drv_bo-&gt;addr will be 0.
    drv_bo-&gt;map = bo-&gt;kmap.virtual;
    drv_bo-&gt;size = bo-&gt;bo.mem.size;
    drv_bo-&gt;priv = bo;

    return 0;
}
</code></pre>
<p>Returned <code>bo</code> by <code>nouveau_bo_new()</code> seems to set the target phyiscal address.</p>
<!--
`/linux/drivers/gpu/drm/nouveau/nouveau_bo.c`
```c
int nouveau_bo_vma_add (struct nouveau_bo *nvbo, struct nouveau_vm *vm, struct nouveau_vma *vma) {
    ...
    nouveau_vm_map(vma, nvbo->bo.mem.mm_node);
    ...
}
```

`/linux/drivers/gpu/drm/nouveau/core/subdev/vm/base.c`
```c
void nouveau_vm_map (struct nouveau_vma *vma, struct nouveau_mem *node) {
    if(node->sg)          nouveau_vm_map_sg_table(vma, 0, node->size << 12, node);
    else {
        if (node->pages)  nouveau_vm_map_sg(vma, 0, node->size << 12, node);
        else              nouveau_vm_at(vma, 0, node);
    }
}
```

In the test, `nouveau_vm_map_sg` is called.

```c
static void
nouveau_vm_map_sg_table(struct nouveau_vma *vma, u64 delta, u64 length,
            struct nouveau_mem *mem)
{
    struct nouveau_vm  vm = vma->vm;
    struct nouveau_vmmgr* vmm = vm->vmm;
    int big = vma->node->type != vmm->spg_shift;
    u32 offset = vma->node->offset + (delta >> 12);
    u32 bits = vma->node->type - 12;
    u32 num  = length >> vma->node->type;
    u32 pde  = (offset >> vmm->pgt_bits) - vm->fpde;
    u32 pte  = (offset & ((1 << vmm->pgt_bits) - 1)) >> bits;
    u32 max  = 1 << (vmm->pgt_bits - bits);
    unsigned m, sglen;
    u32 end, len;
    int i;
    struct scatterlist* sg;

    for_each_sg(mem->sg->sgl, sg, mem->sg->nents, i) {
        struct nouveau_gpuobj* pgt = vm->pgt[pde].obj[big];
        sglen = sg_dma_len(sg) >> PAGE_SHIFT;

        end = pte + sglen;
        if (unlikely(end >= max))
            end = max;
        len = end - pte;

        for (m = 0; m < len; m++) {
            dma_addr_t addr = sg_dma_address(sg) + (m << PAGE_SHIFT);

            vmm->map_sg(vma, pgt, mem, pte, 1, &addr);
            num--;
            pte++;

            if (num == 0)
                goto finish;

```
-->

    </div>
    
    <div class="my-4">
    
    <a href="/tags/cuda/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#cuda</a>
    
    <a href="/tags/research/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#research</a>
    
</div>
    
    
    
    
    
    
    
<div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t">
    <div>
        
        <span class="block font-bold">Previous</span>
        <a href="/2017-05-02/git-basics/" class="block">Git Basics</a>
        
    </div>
    <div class="md:text-right mt-4 md:mt-0">
        
        <span class="block font-bold">Next</span>
        <a href="/2017-04-27/introduction-to-vfio/" class="block">Introduction to VFIO</a>
        
    </div>
</div>

    

<div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "insujang" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>




<div
    class="col-span-2 lg:col-start-2 lg:col-span-6 bg-secondary-bg rounded p-6">
    <h2 class="text-lg font-semibold mb-4">See Also</h2>
    <div class="content">
        
        <a href="/2017-04-27/gpu-architecture-overview/">GPU Architecture Overview</a>
        <br />
        
        <a href="/2017-04-03/pci-express-i/o-system/">PCI Express I/O System</a>
        <br />
        
        <a href="/2017-04-27/introduction-to-vfio/">Introduction to VFIO</a>
        <br />
        
        <a href="/2017-04-21/hooking-an-sgx-encls-leaf-function-call-from-kvm/">Hooking an SGX ENCLS Leaf Function Call from KVM</a>
        <br />
        
        <a href="/2017-04-05/intel-sgx-instructions-in-enclave-initialization/">Intel SGX Instructions in Enclave Initialization</a>
        <br />
        
        <a href="/2017-04-03/intel-sgx-protection-mechanism/">Intel SGX Protection Mechanism</a>
        <br />
        
    </div>
</div>

</div>
<script>
    document.addEventListener('DOMContentLoaded', ()=>{
        hljs.initHighlightingOnLoad();
    })
</script>

      </div>
    
  </main>
  <footer class="pl-scrollbar">
    <div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b">
    <p class="text-sm text-tertiary-text">&copy; 2017 - 2021 Insu Jang &middot;  Powered by the <a href="https://github.com/wangchucheng/hugo-eureka" class="hover:text-eureka">Eureka</a> theme for <a href="https://gohugo.io" class="hover:text-eureka">Hugo</a></p>
</div></div>
  </footer>
</body>

</html>